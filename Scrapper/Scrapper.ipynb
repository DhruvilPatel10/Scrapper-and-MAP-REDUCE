{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b75584ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f24eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url for the page\n",
    "url=\"https://scai.engineering.asu.edu/computer-science-and-engineering-faculty/\"\n",
    "#adding dummy user agent to avoid getting block and access(to avoid error 403)\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36',\n",
    "}\n",
    "#request to url\n",
    "page = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fba7fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list to store data\n",
    "Faculty_Data=[]\n",
    "\n",
    "#opening a text file to store the scrapped data in the format of faculty name, reference link, Bio and courses taught in on horizontal line for each faculty\n",
    "f=open(\"Name_Link.txt\",'w', encoding=\"utf-8\")\n",
    "f.write(\"Name\\t\\t\\t Reference link\\t\\t\\t Bio\\t\\t\\t Courses Taught\\n\\n\")\n",
    "try:\n",
    "    for info in soup.find_all(class_=\"et_pb_text_inner\"):\n",
    "    #finding all <strong> tags\n",
    "        strong_tag= info.find_all(\"strong\")\n",
    "        Faculty_Name=\"\"\n",
    "        for strong_tag in strong_tag:\n",
    "            F_name=strong_tag.text.strip()\n",
    "            if not F_name:\n",
    "                continue\n",
    "            Faculty_Name=F_name\n",
    "            # nearest <p> tag to strong tag\n",
    "            p_tag= strong_tag.find_parent(\"p\")\n",
    "            if p_tag:\n",
    "                R_link=p_tag.find(\"a\",href=True)\n",
    "                if R_link:\n",
    "                    reference_link=R_link.get(\"href\")\n",
    "                    f.write(f\"{reference_link}\\n\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    pass\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f770e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "f = open(\"Name_Link.txt\", 'w', encoding=\"utf-8\")\n",
    "f.write(\"Name\\t\\t\\t Reference link\\n\\n\")\n",
    "biog = open(\"bio.txt\", 'w', encoding=\"utf-8\")\n",
    "biog.write(\"Name\\t\\t\\t BIO\\n\\n\")\n",
    "ct = open(\"courses.txt\", 'w', encoding=\"utf-8\")\n",
    "ct.write(\"Name\\t\\t\\t CoursesTaught\\n\\n\")\n",
    "Data = open(\"DataSet.txt\", 'w', encoding=\"utf-8\")\n",
    "Data.write(\"Name\\t\\t\\t Reference link\\t\\t\\t Bio\\t\\t\\t Courses Taught\\n\\n\")\n",
    "\n",
    "# Find all faculty sections with class 'post-content'\n",
    "main_class = soup.find_all(\"div\", class_=\"post-content\")\n",
    "\n",
    "for m_class in main_class:\n",
    "    # Iterate through all the 'et_pb_text_inner' elements within the faculty section\n",
    "    for info in m_class.find_all(class_=\"et_pb_text_inner\"):\n",
    "        # finding all <strong> tags\n",
    "        strong_tag = info.find_all(\"strong\")\n",
    "        Faculty_Name = \"\"\n",
    "        for strong_tag in strong_tag:\n",
    "            F_name = strong_tag.text.strip()\n",
    "            if not F_name:\n",
    "                continue\n",
    "            Faculty_Name = F_name\n",
    "            # nearest <p> tag to strong tag\n",
    "            p_tag = strong_tag.find_parent(\"p\")\n",
    "            if p_tag:\n",
    "                R_link = p_tag.find(\"a\", href=True)\n",
    "                if R_link:\n",
    "                    reference_link = R_link.get(\"href\")\n",
    "                    bio = \"\"\n",
    "                    courses_taught = set()  # Use a set to avoid duplicates\n",
    "\n",
    "                    try:\n",
    "                        # requesting faculty homepage\n",
    "                        response = requests.get(reference_link, headers=headers)\n",
    "                        faculty_soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "                        # Extract the bio text\n",
    "                        bio_section = faculty_soup.find(\"div\", class_=\"field__item\")\n",
    "                        if bio_section:\n",
    "                            # Finding all <p> tags and joining them to make one para\n",
    "                            bio = ' '.join([p.text.strip() for p in bio_section.find_all(\"p\")])\n",
    "\n",
    "                        # Find all tables with class \"webdir-profile-courses responsive-enabled table\"\n",
    "                        course_tables = faculty_soup.find_all(\"table\", class_=\"webdir-profile-courses responsive-enabled table\")\n",
    "                        for index, course_table in enumerate(course_tables, start=1):\n",
    "                            # Iterate through rows in the table\n",
    "                            for row in course_table.find_all(\"tr\"):\n",
    "                                # Extract all text within the row\n",
    "                                row_text = row.get_text(strip=True)\n",
    "                                # Append non-empty rows to the courses_taught set\n",
    "                                if row_text:\n",
    "                                    courses_taught.add(row_text)\n",
    "\n",
    "                        courses_taught_str = \", \".join(courses_taught)\n",
    "\n",
    "                        f.write(f\"Name:{F_name}\\t\\tLink:{reference_link}\\n\")\n",
    "                        biog.write(f\"Name:{F_name}\\t\\t Bio:{bio}\\n\")\n",
    "                        ct.write(f\"Name:{F_name}\\t\\t Course Taught:{courses_taught_str}\\n\")\n",
    "                        Data.write(f\"Name:{F_name}\\t\\t\\t Link:{reference_link}\\t\\t\\t Bio:{bio}\\t\\t\\tCourse Taught:{courses_taught_str}\\n\")\n",
    "\n",
    "                    except requests.exceptions.RequestException as e:\n",
    "                        pass\n",
    "\n",
    "# Close the output file\n",
    "f.close()\n",
    "biog.close()\n",
    "ct.close()\n",
    "Data.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3236da3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
